{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from pprint import pprint\n",
    "from itertools import chain\n",
    "from collections import defaultdict\n",
    "import googlemaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with 2886 ticketek venues\n",
      "filtered venues: 2871 rows, 2871 unique keys\n",
      "165\n"
     ]
    }
   ],
   "source": [
    "class VenueMatcher:\n",
    "    \n",
    "    \"\"\"\n",
    "    all possibly useful Ticketek venue information is contained in two tables which we join together\n",
    "    \"\"\"\n",
    "    TKT_VENUES = pd.read_csv('data/sample_venue_dim.csv.gz', \n",
    "                             encoding='latin-1', \n",
    "                             error_bad_lines=False, \n",
    "                             sep='\\t')[['pk_venue_dim', 'venue_name', 'venue_desc', 'venue_region_desc']] \\\n",
    "    .join(pd.read_csv('data/sample_VenuesPowerWebAddresses.csv.gz', \n",
    "                             sep='\\t', \n",
    "                             encoding='latin-1')[['venue_name', 'vcName', 'paAddressLine1', 'paAddressLine2','vcRegionName']] \\\n",
    "                             .set_index('venue_name'), on='venue_name', how='left').fillna('')\n",
    "    \n",
    "    # whenever there's no way to tell which state a venue may be in, we will go for a more popular state\n",
    "    PREFERRED_STATES = 'nsw vic qld wa act sa tas nt'.split()\n",
    "    \n",
    "    STATES = {'nsw': 'new south wales', \n",
    "              'act': 'australian capital territory', \n",
    "              'vic': 'victoria',\n",
    "              'tas': 'tasmania',\n",
    "              'wa': 'western australia',\n",
    "              'nt': 'northern teritory',\n",
    "              'sa': 'south australia',\n",
    "              'qld': 'queensland'}\n",
    "    \n",
    "    # now another dictionary, full to abbreviated\n",
    "    STATES_ = {v: k for k, v in STATES.items()}\n",
    "    \n",
    "    SUBURBS = json.load(open('data/aus_suburbs_auspost_APR2017.json'))\n",
    "    \n",
    "    # words to catch useless venues\n",
    "    BAD_WORDS = set(\"\"\"games ticketek voucher circus cruise cirque bus events  \n",
    "                        buses cruises prosessing balloon series coach tent trail upsell \n",
    "                        stattion fence pier reserve office memberships miscelaneous festival interchange\"\"\".split())\n",
    "    \n",
    "    BAD_TYPES = set('political colloquial_area locality natural_feature'.split())\n",
    "    \n",
    "    # we'll be collecting unusual venues to review and put into a training dataset\n",
    "    SUSPICIOUS_VENUES = set()\n",
    "    \n",
    "    # sometimes we'd like to pick the search resuts of a particular type only\n",
    "    ENFORCED_TYPES = {'winery': 'food', 'vineyard': 'food', 'zoo': 'zoo'}\n",
    "    \n",
    "    gmaps = googlemaps.Client(**json.load(open('credentials/google.json')))\n",
    "    \n",
    "    def __init__(self, read_local=True):\n",
    "        \n",
    "        self.tkt_venues = [] if not read_local else json.load(open('data/tkt_venues.json'))\n",
    "        \n",
    "        print(f'working with {len(self.tkt_venues)} ticketek venues')\n",
    "    \n",
    "    def filter_tables(self):\n",
    "        \n",
    "        # ignore venues that have anything but letters in thir CODES (these are typically like ABC or DFE)\n",
    "        VenueMatcher.TKT_VENUES = VenueMatcher.TKT_VENUES[VenueMatcher.TKT_VENUES['venue_name'].str.isalpha()]\n",
    "        # ignore venues that have inappropriate words in their descriptions \n",
    "        flagged_ = VenueMatcher.TKT_VENUES[VenueMatcher.TKT_VENUES['venue_desc'].apply(lambda _: bool(VenueMatcher.BAD_WORDS & set(_.lower().split())))]\n",
    "        \n",
    "        VenueMatcher.SUSPICIOUS_VENUES.update(set(flagged_['venue_desc'].str.lower()))\n",
    "        \n",
    "        VenueMatcher.TKT_VENUES = VenueMatcher.TKT_VENUES[~VenueMatcher.TKT_VENUES['venue_desc'] \\\n",
    "                                                          .apply(lambda _: len(VenueMatcher.BAD_WORDS & set(_.lower().split())) > 0)]\n",
    "        \n",
    "        print(f'filtered venues: {len(VenueMatcher.TKT_VENUES)} rows, {len(set(VenueMatcher.TKT_VENUES.pk_venue_dim))} unique keys')\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def _find_state(self, st):\n",
    "        \"\"\"\n",
    "        find state names in string st; returns a SET of identified names\n",
    "        \"\"\"\n",
    "        \n",
    "        states_found = set()\n",
    "        \n",
    "        st_norm = self._normalize(st)\n",
    "        \n",
    "        for s in (set(VenueMatcher.STATES) | set(VenueMatcher.STATES_)):\n",
    "            try:\n",
    "                states_found.add(re.search(r'\\b' + s + r'\\b', st_norm).group(0))\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "        if states_found: # note that these may be either the full or abbreviated state names\n",
    "            # return full state names to avoid rare ambiguities like WA (Australia) and WA (the US)\n",
    "            return {s if s not in VenueMatcher.STATES_ else VenueMatcher.STATES_[s] for s in states_found}\n",
    "        \n",
    "        return states_found\n",
    "    \n",
    "    def _find_suburb(self, st):\n",
    "        \"\"\"\n",
    "        find suburb names in string st; returns a set of tuples (suburb, state)\n",
    "        \"\"\"\n",
    "        st_norm = self._normalize(st)\n",
    "        \n",
    "        suburbs_found = set()\n",
    "        \n",
    "        words_ = st_norm.split()\n",
    "        \n",
    "        for i, w in enumerate(words_):\n",
    "            \n",
    "            # take first letter of the word\n",
    "            l1_ = w[0]\n",
    "            \n",
    "            # if any suburb names start from this letter..\n",
    "            if l1_ in VenueMatcher.SUBURBS:\n",
    "            \n",
    "                for r in VenueMatcher.SUBURBS[l1_]:\n",
    "                    \n",
    "                    try:\n",
    "                        suburbs_found.add((re.search(r'\\b' + r['name'] + r'\\b', ' '.join(words_[i:])).group(0), r['state']))\n",
    "                    except:\n",
    "                        continue\n",
    "                        \n",
    "        return suburbs_found \n",
    "    \n",
    "    def find_venue_state(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        look at the available Tiketek venue deacription fields and try to figure out what state the venue may\n",
    "        be in; if this isn't clear, collect candidate states\n",
    "        \"\"\"\n",
    "       \n",
    "        for i, row in enumerate(VenueMatcher.TKT_VENUES.iterrows(),1):\n",
    "            \n",
    "            if i%100 == 0:\n",
    "                print(f'processing row {i}...')\n",
    "                \n",
    "            this_venue = defaultdict()\n",
    "        \n",
    "            this_venue['name'] = self._normalize(row[1]['venue_desc'])\n",
    "            this_venue['code'] = [row[1]['venue_name'].lower()]\n",
    "            \n",
    "            # search for state according to priority until found in one of the columns,\n",
    "            # then stop\n",
    "            \n",
    "            for c in ['venue_desc', 'vcRegionName','venue_region_desc']:\n",
    "                \n",
    "                # note: set below may be empty if no states found\n",
    "                candidate_states = self._find_state(self._normalize(row[1][c]))\n",
    "                \n",
    "                if len(candidate_states) == 1:\n",
    "                    # a single candidate state\n",
    "                    this_venue['state'] = candidate_states.pop()\n",
    "                    break\n",
    "                else: \n",
    "                    # many or no candidate states; need to find suburb \n",
    "                    for c in ['venue_desc', 'venue_region_desc']:\n",
    "                        \n",
    "                        # note that sub_state may be an empty set\n",
    "                        suburb_state_tuples = self._find_suburb(self._normalize(row[1][c]))\n",
    "                        \n",
    "                        # suppose a single suburb found\n",
    "                        if len(suburb_state_tuples) == 1:\n",
    "                            \n",
    "                            if len(candidate_states) > 0:\n",
    "                                #  enough if its state is among candidate states\n",
    "                                if list(suburb_state_tuples)[0][1] in candidate_states:\n",
    "                                    this_venue['state'] = list(suburb_state_tuples)[0][1]\n",
    "                            else:\n",
    "                                # if no candidate states\n",
    "                                this_venue['state'] = list(suburb_state_tuples)[0][1]\n",
    "                                \n",
    "                            break\n",
    "                        \n",
    "                        # what if more than one suburb found?\n",
    "                        elif len(suburb_state_tuples) > 1:\n",
    "                            \n",
    "                            # suppose no candidate states\n",
    "                            if not candidate_states:\n",
    "                                \n",
    "                                # if different suburbs in THE SAME state\n",
    "                                _ = {s[1] for s in suburb_state_tuples}\n",
    "                                \n",
    "                                if len(_) == 1:\n",
    "                                    this_venue['state'] = _.pop()\n",
    "                                    break\n",
    "                                    \n",
    "                                else:\n",
    "                                    # return the longest (in terms of the number of words in suburb name) tuple (first found)\n",
    "                                    longest_sub = max(suburb_state_tuples, key=lambda x: len(x[1].split()))\n",
    "                                    # only if the suburb name has AT LEAST TWO words\n",
    "                                    if len(longest_sub[0].split()) > 1:\n",
    "                                        this_venue['state'] = longest_sub[1]\n",
    "                                    else:\n",
    "                                        # simply add a list of candidate states\n",
    "                                        this_venue['state_'] = list(_)\n",
    "                                    break\n",
    "                            else:\n",
    "                                # if we have multiple candidate states AND multiple suburbs\n",
    "                                for ss in suburb_state_tuples:\n",
    "                                    # pick the first suburb that has its state among state candidates\n",
    "                                    if ss[1] in candidate_states:\n",
    "                                        this_venue['state'] = ss[1]\n",
    "                                        break\n",
    "                                        \n",
    "            self.tkt_venues.append(this_venue)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def merge_codes(self, on='name'):\n",
    "        \"\"\"\n",
    "        merge Ticketek venues with multiple codes\n",
    "        \"\"\"\n",
    "        \n",
    "        venues_ = []\n",
    "        # venue names already processed\n",
    "        nms = set()\n",
    "        \n",
    "        for v in self.tkt_venues:\n",
    "            \n",
    "            if v[on] not in nms:\n",
    "                venues_.append(v)\n",
    "                nms.add(v[on])\n",
    "            else:\n",
    "                # this name is already available, must be under another code\n",
    "                for v_ in venues_:\n",
    "                    if v_[on] == v[on]:\n",
    "                        v_['code'].extend(v['code'])\n",
    "                        v_['code'] = list(set(v_['code']))\n",
    "                        \n",
    "        self.tkt_venues = venues_\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def _normalize(self, st):\n",
    "        \"\"\"\n",
    "        normalize a string st\n",
    "        \"\"\"\n",
    "        st = st.lower()\n",
    "        # replace separators with white spaces\n",
    "        st = re.sub(r'[-/_.]', ' ', st)\n",
    "        # keep only letters, numbers and white spaces\n",
    "        st = ''.join([l for l in st if str(l).isalnum() or str(l).isspace()])\n",
    "        st = re.sub(r'\\s{2,}', ' ', st)\n",
    "        \n",
    "        return st\n",
    "    \n",
    "    def _get_fields(self, res):\n",
    "        \"\"\"\n",
    "        extract fields from a search response\n",
    "        \"\"\"\n",
    "        up = {'place_id': res.get('place_id', None),\n",
    "                                  'address': res.get('formatted_address', None),\n",
    "                                  'venue_type': res.get('types', None),\n",
    "                                  'coordinates': res['geometry']['location']}\n",
    "        return up\n",
    "        \n",
    "    def get_place_id(self, local_file='data/tkt_venues.json'):\n",
    "        \n",
    "        \"\"\"\n",
    "        ask google maps to find places by name; the key here is to hopefully\n",
    "        grab a place id\n",
    "        \"\"\"\n",
    "        \n",
    "        print('retrieving place ids...')\n",
    "        \n",
    "        if local_file:\n",
    "            \n",
    "            self.tkt_venues = json.load(open(local_file))\n",
    "            print(f'collected {len(self.tkt_venues)} venues from the locally saved file {local_file}')\n",
    "            print(f'{sum([\"place_id\" in v for v in self.tkt_venues])} of these already have place_ids')\n",
    "\n",
    "        for i, v in enumerate(self.tkt_venues,1):\n",
    "            \n",
    "            # we want to query Google Maps for the venues that don't have a place_id yet\n",
    "            \n",
    "            if 'place_id' not in v:\n",
    "                \n",
    "                print(v['name'])\n",
    "                      \n",
    "                if 'state' in v:\n",
    "                \n",
    "                    # so we have a specific state..\n",
    "                    try:\n",
    "                        qr_ = self.gmaps.geocode(' '.join([v['name'], VenueMatcher.STATES[v['state']], 'australia']))\n",
    "                    except:\n",
    "                        print(f'no response, probably exceeded quota')\n",
    "                        json.dump(self.tkt_venues, open('data/tkt_venues.json','w'))\n",
    "                        break\n",
    "                \n",
    "                    if qr_:\n",
    "                        v.update(self._get_fields(qr_[0]))\n",
    "            \n",
    "                else:\n",
    "                \n",
    "                    # problem with the state, need to consider multiple candidates\n",
    "                \n",
    "                    for possible_state in v['state_']:\n",
    "                        \n",
    "                        try:\n",
    "                            qr_ = self.gmaps.geocode(' '.join([v['name'], VenueMatcher.STATES[possible_state], 'australia']))\n",
    "                        except:\n",
    "                            print(f'no response, probably EXCEEDED GOOGLE API QUOTA?')\n",
    "                            json.dump(vm.tkt_venues, open('data/tkt_venues.json','w'))\n",
    "                            break\n",
    "                    \n",
    "                        if qr_:\n",
    "                            \n",
    "                            q_top_result = None\n",
    "                            \n",
    "                            for r in qr_:\n",
    "                                if VenueMatcher.BAD_TYPES & set(r.get('types',[])):\n",
    "                                    continue\n",
    "                                else:\n",
    "                                    q_top_result = r\n",
    "                                 \n",
    "                            if q_top_result:\n",
    "                                \n",
    "                                for address_component in q_top_result['address_components']:\n",
    "                                    # if the state we search for is in \n",
    "                                    # the result components, we say it's a suitable result\n",
    "                                \n",
    "                                    if address_component['short_name'].strip().lower() == possible_state:\n",
    "                                        \n",
    "                                        v.update(self._get_fields(q_top_result))\n",
    "                                        \n",
    "                                        break\n",
    "        \n",
    "        json.dump(self.tkt_venues, open('data/tkt_venues.json','w'))\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def get_place_details(self, local_file='data/tkt_venues.json'):\n",
    "        \n",
    "        \"\"\"\n",
    "        ask google maps for place details using a place id; \n",
    "        \"\"\"\n",
    "        \n",
    "        print('retirieving place details...')\n",
    "        \n",
    "        if local_file:\n",
    "            \n",
    "            self.tkt_venues = json.load(open(local_file))\n",
    "            print(f'collected {len(self.tkt_venues)} venues from the locally saved file {local_file}')\n",
    "            print(f'{sum([\"name_googlemaps\" in v for v in self.tkt_venues])} of these have googlemaps name')\n",
    "        \n",
    "        for i, v in enumerate(self.tkt_venues, 1):\n",
    "            \n",
    "            if i%100 == 0:\n",
    "                print(f'venue {i}: {v[\"name\"].upper()}...')\n",
    "            \n",
    "            if ('place_id' in v) and ('name_googlemaps' not in v):     \n",
    "                \n",
    "                try:\n",
    "                    place_details = self.gmaps.place(v['place_id'])['result']\n",
    "                except:\n",
    "                    print(f'can\\'t get any place details for place_id {v[\"name\"]}. EXCEEDED QUOTA?')\n",
    "                    json.dump(self.tkt_venues, open('data/tkt_venues.json','w'))\n",
    "                    return self                \n",
    "                      \n",
    "                try:\n",
    "                    v.update({'name_googlemaps': place_details['name'].lower()})\n",
    "                except:\n",
    "                    print(f'no googlemap name found!')\n",
    "\n",
    "                try:\n",
    "                      v.update({'opening_hours': [d.lower() for d in place_details['opening_hours']['weekday_text']]})\n",
    "                except:\n",
    "                      print(f'no opening_hours found!')\n",
    "\n",
    "                try:     \n",
    "                     v.update({'rating': float(place_details['rating'])})\n",
    "                except:\n",
    "                     print(f'no rating found!')\n",
    "\n",
    "                try:\n",
    "                    v.update({'url_googlemaps': place_details['url']})\n",
    "                except:\n",
    "                    print(f'no url found!')\n",
    "\n",
    "                try:\n",
    "                    v.update({'website': place_details['website']})\n",
    "                except:\n",
    "                     print(f'no website found!') \n",
    "        \n",
    "        \n",
    "        json.dump(self.tkt_venues, open('data/tkt_venues.json','w'))\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def clear_suspects(self):\n",
    "        \"\"\"\n",
    "        remove all fields but name, code and state/state candidates for dubious venues\n",
    "        \"\"\"\n",
    "        \n",
    "        print('looking for suspicious venues..')\n",
    "        \n",
    "        vs_ = [] \n",
    "        \n",
    "        for v in self.tkt_venues:\n",
    "            \n",
    "            if set(v.get(\"venue_type\", [])) & VenueMatcher.BAD_TYPES:\n",
    "                \n",
    "                if 'name' not in v:\n",
    "                    continue\n",
    "                \n",
    "                fields_ = {'name': v['name'],\n",
    "                           'code': v['code']}\n",
    "                if 'state' in v:\n",
    "                    fields_.update({'state': v['state']})\n",
    "                if 'state_' in v:\n",
    "                    fields_.update({'state_': v['state_']})\n",
    "                    \n",
    "                vs_.append(fields_)\n",
    "                \n",
    "                VenueMatcher.SUSPICIOUS_VENUES.add(v['name'])\n",
    "                \n",
    "            else:\n",
    "                vs_.append(v)\n",
    "                \n",
    "        self.tkt_venues = vs_\n",
    "        \n",
    "        json.dump(self.tkt_venues, open('data/tkt_venues.json','w'))\n",
    "        \n",
    "        print(f'flagged venues: {len(VenueMatcher.SUSPICIOUS_VENUES)}')\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def create_dataset(self):\n",
    "        \n",
    "        good_ = set()\n",
    "        \n",
    "        for v in self.tkt_venues:\n",
    "            if 'place_id' in v:\n",
    "                good_.add(v['name'])\n",
    "        \n",
    "        pd.DataFrame(pd.concat([pd.DataFrame({'venue': list(good_), 'is_ok': [1]*len(good_)}),\n",
    "                               pd.DataFrame({'venue': list(VenueMatcher.SUSPICIOUS_VENUES), 'is_ok': [0]*len(VenueMatcher.SUSPICIOUS_VENUES)})])).sample(frac=1.).to_csv('venue_db.csv', index=False)\n",
    "                \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    vm = VenueMatcher().filter_tables()\n",
    "    #.get_place_details()\n",
    "#     .get_place_id()\n",
    "#     .get_place_details()\n",
    "    print(len(vm.SUSPICIOUS_VENUES)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'address_components': [{'long_name': '503',\n",
      "                          'short_name': '503',\n",
      "                          'types': ['street_number']},\n",
      "                         {'long_name': 'Goonoo Goonoo Road',\n",
      "                          'short_name': 'Goonoo Goonoo Rd',\n",
      "                          'types': ['route']},\n",
      "                         {'long_name': 'Tamworth',\n",
      "                          'short_name': 'Tamworth',\n",
      "                          'types': ['locality', 'political']},\n",
      "                         {'long_name': 'Tamworth Regional Council',\n",
      "                          'short_name': 'Tamworth Regional',\n",
      "                          'types': ['administrative_area_level_2',\n",
      "                                    'political']},\n",
      "                         {'long_name': 'New South Wales',\n",
      "                          'short_name': 'NSW',\n",
      "                          'types': ['administrative_area_level_1',\n",
      "                                    'political']},\n",
      "                         {'long_name': 'Australia',\n",
      "                          'short_name': 'AU',\n",
      "                          'types': ['country', 'political']},\n",
      "                         {'long_name': '2340',\n",
      "                          'short_name': '2340',\n",
      "                          'types': ['postal_code']}],\n",
      "  'formatted_address': '503 Goonoo Goonoo Rd, Tamworth NSW 2340, Australia',\n",
      "  'geometry': {'location': {'lat': -31.1339781, 'lng': 150.9203505},\n",
      "               'location_type': 'ROOFTOP',\n",
      "               'viewport': {'northeast': {'lat': -31.1326291197085,\n",
      "                                          'lng': 150.9216994802915},\n",
      "                            'southwest': {'lat': -31.1353270802915,\n",
      "                                          'lng': 150.9190015197085}}},\n",
      "  'place_id': 'ChIJW8pWdVuYCmsRi-kyYmBpOVs',\n",
      "  'types': ['establishment', 'point_of_interest']}]\n"
     ]
    }
   ],
   "source": [
    "pprint(vm.gmaps.geocode('australian equine and livestock events centre' + ' ' + 'new south wales australia'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
